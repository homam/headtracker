<!doctype html>
<html lang="en">
	<head>
		<title>facetracking</title>
		<meta http-equiv="X-UA-Compatible" content="IE=Edge"/>
		<meta charset="utf-8">
		<style>
			body {
				background-color: #f0f0f0;
				margin-left: 10%;
				margin-right: 10%;
				margin-top: 5%;
				width: 40%;
				overflow: hidden;
				font-family: "Helvetica", Arial, Serif;
				position: relative;
			}
			#video-container {
				position: relative;;
			}
			#overlay{
				position: absolute;
				top: 0px;
				z-index: 100001;
				display: block;
			}
		</style>
	</head>
	<body>
		<script src="../headtrackr.js"></script>
		
		<div id="video-container">
			<video id="vid" autoplay loop width="320" height="240"></video>
			<canvas id="overlay"></canvas>
		</div>
		<img id="photo" />
		
		<p id='gUMMessage'></p>
		<p>Status : <span id='headtrackerMessage'></span></p>
		<p><input type="button" onclick="htracker.stop();htracker.start();" value="reinitiate facedetection"></input>
		
		<script>
		  // set up video and canvas elements needed
		
			var videoInput = document.getElementById('vid');
			var canvasInput = document.createElement('canvas');
			canvasInput.width = videoInput.width;
			canvasInput.height = videoInput.height;
			var canvasOverlay = document.getElementById('overlay');
			canvasOverlay.width = videoInput.width;
			canvasOverlay.height = videoInput.height;
			var overlayContext = canvasOverlay.getContext('2d');

			// add some custom messaging
			
			statusMessages = {
				"whitebalance" : "checking for stability of camera whitebalance",
				"detecting" : "Detecting face",
				"hints" : "Hmm. Detecting the face is taking a long time",
				"redetecting" : "Lost track of face, redetecting",
				"lost" : "Lost track of face",
				"found" : "Tracking face"
			};
			
			supportMessages = {
				"no getUserMedia" : "Unfortunately, <a href='http://dev.w3.org/2011/webrtc/editor/getusermedia.html'>getUserMedia</a> is not supported in your browser. Try <a href='http://www.opera.com/browser/'>downloading Opera 12</a> or <a href='http://caniuse.com/stream'>another browser that supports getUserMedia</a>. Now using fallback video for facedetection.",
				"no camera" : "No camera found. Using fallback video for facedetection."
			};
			
			document.addEventListener("headtrackrStatus", function(event) {
				if (event.status in supportMessages) {
					var messagep = document.getElementById('gUMMessage');
					messagep.innerHTML = supportMessages[event.status];
				} else if (event.status in statusMessages) {
					var messagep = document.getElementById('headtrackerMessage');
					messagep.innerHTML = statusMessages[event.status];
				}
			}, true);
			
			// the face tracking setup
			
			var htracker = new headtrackr.Tracker({calcAngles : true, ui : false, headPosition : false});
			htracker.init(videoInput, canvasInput);
			htracker.start();

			var gradhat = new Image();
			gradhat.src = "gradhat.png";
			gradhat.addEventListener('load', function() {
				console.log(gradhat.width, gradhat.height);
				gradhat.dataset.loaded = true;
			});
			
			// for each facetracking event received draw rectangle around tracked face on canvas
			
			document.addEventListener("facetrackingEvent", function( event ) {
				// clear canvas
				overlayContext.clearRect(0,0,videoInput.width,videoInput.height);
				// once we have stable tracking, draw rectangle
				if (event.detection == "CS") {
					overlayContext.save();
					overlayContext.translate(event.x, event.y)
					overlayContext.rotate(event.angle-(Math.PI/2));
					//overlayContext.strokeStyle = "#00CC00";
					//overlayContext.strokeRect((-(event.width/2)) >> 0, (-(event.height/2)) >> 0, event.width, event.height);
					if(!!gradhat.dataset.loaded) {
						var hatWidth = event.width*1.8;
						var hatHeight = gradhat.height * hatWidth/gradhat.width
						overlayContext.drawImage(gradhat,-hatWidth/2,-event.height/2-hatHeight*.66,hatWidth,hatHeight)
					}
					overlayContext.restore();
				}
			});

		  	function takepicture() {
			    var snapshotCanvas = document.createElement("canvas");
			    snapshotCanvas.width = videoInput.width*1;
			    snapshotCanvas.height = videoInput.height*1;
			    var snapshotContext = snapshotCanvas.getContext('2d');
			    snapshotContext.drawImage(videoInput, 0, 0, snapshotCanvas.width, snapshotCanvas.height);
			    snapshotContext.drawImage(overlay, 0, 0, snapshotCanvas.width, snapshotCanvas.height);
			    var data = snapshotCanvas.toDataURL('image/png');
			    var photo =document.getElementById('photo');
			    photo.src = data;
			}
		</script>
	</body>
</html>